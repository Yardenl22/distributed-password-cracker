# **Distributed Password Cracker**

A fully distributed system for cracking MD5 hashes of phone numbers (`05X-XXXXXXX`).
The project utilizes **FastAPI**, **RabbitMQ**, **Redis**, and a set of **asynchronous workers** to efficiently distribute and process hash-cracking tasks.

---

## **Features**
- Distributed Hash Cracking ‚Äì Work is distributed among multiple workers for parallel processing.
- Scalable Architecture ‚Äì Can dynamically scale minion workers and result processors.
- Task Queueing with RabbitMQ ‚Äì Ensures efficient task distribution and load balancing.
- Redis-based Status Storage ‚Äì Enables fast retrieval of task statuses.
- Persistent Storage ‚Äì Redis and RabbitMQ use **PVC (Persistent Volumes)** to prevent data loss.
- Fault-Tolerant System ‚Äì Implements retry mechanisms and exception handling for stability.
- Fully Containerized with Docker ‚Äì Just **pull, run, and deploy** with `docker-compose`.

---

## **Installation & Setup**
### **1Ô∏è‚É£ Clone the Repository**
```bash
git clone https://github.com/Yardenl22/distributed-password-cracker.git
cd distributed-password-cracker
```

### **2Ô∏è‚É£ Build & Start the System**
```bash
docker-compose up --build
```
This will:
- Start **FastAPI** on `http://localhost:8080`
- Initialize **RabbitMQ** and **Redis**
- Run **5 minion workers** and **2 result processors**

### **3Ô∏è‚É£ Check Running Containers**
```bash
docker ps
```

### **4Ô∏è‚É£ Access the API**
- Open **`http://localhost:8080/docs`** in your browser.

### **5Ô∏è‚É£ Submit a Hash for Cracking**
```bash
curl -X POST "http://localhost:8080/upload_hashes" \
     -H "Content-Type: application/json" \
     -d '{"hashes": [
            "1d0b28c7e3ef0ba9d3c04a4183b576ac",
            "0da74e79f730b74d0b121f6817b13eac",
            "4fcaeb8f267533389d1ce65053c631df",
            "0eecc2b2ff6160bc7c6d9d601f08529a",
            "1a1674fc1f2ce010f161b4cd1ad80939"
          ]
        }'
```

### **6Ô∏è‚É£ Check Task Status**
```bash
curl -X GET "http://localhost:8080/task_status/your_task_id"
```

### **7Ô∏è‚É£ Access RabbitMQ UI**
- Open **`http://localhost:15672`**
- Username: `user`, Password: `password`

### **8Ô∏è‚É£ Scaling Workers**
Need more power? Scale workers dynamically:
```bash
docker-compose up --scale minion=10
```
This increases minion workers from 5 to 10.

---

## **API Usage**

| **Method** | **Endpoint**             | **Description** |
|-----------|--------------------------|-----------------|
| **POST**  | `/upload_hashes`, `/upload_file`       | Submit MD5 hashes for cracking. |
| **GET**   | `/task_status/{task_id}` | Retrieve the status of a submitted task. |

---

## **Code Architecture & Design Decisions**

The system follows a **modular and distributed design** to efficiently distribute computational workloads across multiple workers. 
The **FastAPI master server** manages tasks, while **minion workers** handle hash-cracking in parallel.

### **Key Code Components**

#### **Storage System**
The `storage` module manages task result storage. It currently supports JSON-based storage but is designed for easy expansion to databases like MongoDB.

- **`BaseStorage` (Abstract Class)** ‚Äì Defines required storage operations.
- **`JSONStorage`** ‚Äì Implements persistent storage in JSON format.
- **`StorageFactory`** ‚Äì Dynamically selects the storage backend.

#### **Application Runner**
The system is designed to run as a **distributed microservices architecture**:
- `master/app.py` ‚Äì Starts the FastAPI master server.
- `minion/worker.py` ‚Äì Listens to RabbitMQ and processes tasks.
- `result_processor.py` ‚Äì Receives and stores cracked passwords.

#### **Exception Handling**
- **Retries & Graceful Failures** ‚Äì Implements retries for failed tasks.

---

## **Future Enhancements**
- Task Status Updates in Redis ‚Äì Add live progress tracking for each hash-cracking task.
- Database Integration ‚Äì Store cracked passwords in a relational DB instead of JSON.
- Advanced Load Balancing ‚Äì Optimize worker distribution based on real-time load metrics.

---

üöÄ **This system is ready for deployment and can easily scale with additional minion workers!**
